{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\muhammadawais.naeem\\AppData\\Roaming\\nltk_data\n",
      "[nltk_data]     ...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\muhammadawais.naeem\\AppData\\Roaming\\nltk_data\n",
      "[nltk_data]     ...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\muhammadawais.naeem\\AppData\\Roaming\\nltk_data\n",
      "[nltk_data]     ...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\muhammadawais.naeem\\AppData\\Roaming\\nltk_data\n",
      "[nltk_data]     ...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('words')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Abstract Name</th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>###24491034</td>\n",
       "      <td>The emergence of HIV as a chronic condition me...</td>\n",
       "      <td>BACKGROUND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>###24491034</td>\n",
       "      <td>This paper describes the design and evaluation...</td>\n",
       "      <td>BACKGROUND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>###24491034</td>\n",
       "      <td>This study is designed as a randomised control...</td>\n",
       "      <td>METHODS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>###24491034</td>\n",
       "      <td>The intervention group will participate in the...</td>\n",
       "      <td>METHODS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>###24491034</td>\n",
       "      <td>The program is based on self-efficacy theory a...</td>\n",
       "      <td>METHODS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Abstract Name                                               Text       Label\n",
       "0   ###24491034  The emergence of HIV as a chronic condition me...  BACKGROUND\n",
       "1   ###24491034  This paper describes the design and evaluation...  BACKGROUND\n",
       "2   ###24491034  This study is designed as a randomised control...     METHODS\n",
       "3   ###24491034  The intervention group will participate in the...     METHODS\n",
       "4   ###24491034  The program is based on self-efficacy theory a...     METHODS"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('Dataset/train.csv')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Size: 299826\n",
      "Max Sequence Length: 338\n"
     ]
    }
   ],
   "source": [
    "word_to_idx = {}\n",
    "idx = 0\n",
    "max_sequence_length = 0\n",
    "\n",
    "for sent in train_data['Text']:\n",
    "    # Tokenize the text\n",
    "    sent_split = sent.split()\n",
    "\n",
    "    # Record the max sequence length to be later used for padding or truncating\n",
    "    if len(sent_split) > max_sequence_length:\n",
    "        max_sequence_length = len(sent_split)\n",
    "\n",
    "    # Record the unique index for each word in the textual descriptions\n",
    "    for word in sent_split:\n",
    "        if word not in word_to_idx:\n",
    "            word_to_idx[word] = idx\n",
    "            idx = idx + 1\n",
    "\n",
    "# Record the total input size to be length of the indexed dictionary\n",
    "input_size = len(word_to_idx) + 2 # to be on the safer side\n",
    "print(f\"Input Size: {input_size}\")\n",
    "print(f\"Max Sequence Length: {max_sequence_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_or_truncate(sequence, length):\n",
    "    if len(sequence) < length:\n",
    "        return torch.cat([sequence, torch.zeros(length - len(sequence), dtype=torch.long)])\n",
    "    else:\n",
    "        return sequence[:length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The transform function wil skip the word which is not present in the initial dictionary\n",
    "def text_transform_func(text):\n",
    "    sentence_onehot = [word_to_idx[word] for word in text.split() if word in word_to_idx]\n",
    "    sentence_onehot = torch.tensor(sentence_onehot, dtype=torch.long)\n",
    "    sentence_onehot = pad_or_truncate(sentence_onehot, max_sequence_length)\n",
    "    return sentence_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AbstractsModel(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, num_layers, num_classes=5):\n",
    "        super(AbstractsModel, self).__init__()\n",
    "        # Specifying Embedding and GRU layers to process the text data\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.gru = nn.GRU(embedding_size, hidden_size, num_layers, batch_first=True)\n",
    "        # Specifying Linear Layer to process the text data after the RNN Layer\n",
    "        self.fc1 = nn.Linear(hidden_size, 32)\n",
    "        self.fc2 = nn.Linear(32, 16)\n",
    "        self.fc3 = nn.Linear(16, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Applying embedding and RNN operation to text data for extraction of features\n",
    "        out = self.embedding(x)\n",
    "        out, _ = self.gru(out)\n",
    "        # Apply mean pooling\n",
    "        out = torch.mean(out, dim=1)\n",
    "        # A fully connected layer to predict the outputs\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initializing the Model Settings\n",
    "embedding_size = 200\n",
    "hidden_size = 64\n",
    "num_layers = 2\n",
    "input_size = 468389\n",
    "\n",
    "# Create an instance of the abstract model and load the saved model\n",
    "abstract_model = AbstractsModel(input_size, embedding_size, hidden_size, num_layers)\n",
    "abstract_model.load_state_dict(torch.load('abstract_model.pth', map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_abstract = '''\n",
    "The aim of this paper is to map the scientific landscape related to cancer research worldwide between 2012 and 2017. We use scientific publication data from Web of Science Core Collection and combine bibliometrics and social network analysis techniques to identify the most relevant journals, research areas, countries and research organizations in cancer scientific landscape. The results show: Oncotarget as the journal with most publications; a significant increase in China’s publications, reaching United States’ publications in 2017; MD Cancer Center, University of California and Harvard University as organizations with most publications; cell biology as the most frequent research area; breast, lung and colorectal cancer as the most frequent keywords; high density of co-authorship between organizations in the West, especially in the US, and low density between organizations in Asian and lower and medium income countries. Our findings can be used to guide a global knowledge platform guiding policy, planning and funding decisions as well as to establish new institutional collaborations.\n",
    "'''\n",
    "\n",
    "# Split the abstract on the period (.)\n",
    "abstract_lines = example_abstract.split('.')\n",
    "\n",
    "# Replace the new line characters and remove the extra spaces at the start/end\n",
    "abstract_lines = [line.replace('\\n','').strip() for line in abstract_lines]\n",
    "\n",
    "# Remove the empty lines \n",
    "abstract_lines = [line for line in abstract_lines if len(line) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Background: ['The aim of this paper is to map the scientific landscape related to cancer research worldwide between 2012 and 2017', 'We use scientific publication data from Web of Science Core Collection and combine bibliometrics and social network analysis techniques to identify the most relevant journals, research areas, countries and research organizations in cancer scientific landscape']\n",
      "Objective: []\n",
      "Methods: []\n",
      "Results: []\n",
      "Conclusions: ['The results show: Oncotarget as the journal with most publications; a significant increase in China’s publications, reaching United States’ publications in 2017; MD Cancer Center, University of California and Harvard University as organizations with most publications; cell biology as the most frequent research area; breast, lung and colorectal cancer as the most frequent keywords; high density of co-authorship between organizations in the West, especially in the US, and low density between organizations in Asian and lower and medium income countries', 'Our findings can be used to guide a global knowledge platform guiding policy, planning and funding decisions as well as to establish new institutional collaborations']\n"
     ]
    }
   ],
   "source": [
    "background = []\n",
    "objective = []\n",
    "methods = []\n",
    "results = []\n",
    "conclusions = []\n",
    "\n",
    "for text in abstract_lines:\n",
    "    text_tensor = text_transform_func(text)\n",
    "    text_tensor = text_tensor.reshape(1, -1)\n",
    "    output = abstract_model(text_tensor)\n",
    "    label = np.argmax(output.detach().cpu().numpy(), axis=1)\n",
    "    \n",
    "    if label == 0:\n",
    "        background.append(text)\n",
    "    elif label == 1:\n",
    "        objective.append(text)\n",
    "    elif label == 2:\n",
    "        methods.append(text)\n",
    "    elif label == 3:\n",
    "        results.append(text)\n",
    "    elif label == 4:\n",
    "        conclusions.append(text)\n",
    "\n",
    "print(f'Background: {background}')\n",
    "print(f'Objective: {objective}')\n",
    "print(f'Methods: {methods}')\n",
    "print(f'Results: {results}')\n",
    "print(f'Conclusions: {conclusions}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_all_fields():\n",
    "    abstract_text.delete(1.0, tk.END)\n",
    "    abstract_status_label[\"text\"] = \"\"\n",
    "    background_text.delete(1.0, tk.END)\n",
    "    objective_text.delete(1.0, tk.END)\n",
    "    methods_text.delete(1.0, tk.END)\n",
    "    results_text.delete(1.0, tk.END)\n",
    "    conclusions_text.delete(1.0, tk.END)\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model():\n",
    "    \n",
    "     # Firstly clear all the result text entries\n",
    "     abstract_status_label[\"text\"] = \"\"\n",
    "     background_text.delete(1.0, tk.END)\n",
    "     objective_text.delete(1.0, tk.END)\n",
    "     methods_text.delete(1.0, tk.END)\n",
    "     results_text.delete(1.0, tk.END)\n",
    "     conclusions_text.delete(1.0, tk.END)\n",
    "     \n",
    "     # Read the text in abstract_text\n",
    "     abstract_text_value = abstract_text.get(\"1.0\", \"end-1c\").strip()\n",
    "    \n",
    "     if len(abstract_text_value) > 0: #abstract has some valid text in the box\n",
    "          abstract_status_label[\"foreground\"] = \"green\"\n",
    "          abstract_status_label[\"text\"] = \"Valid Abstract\"\n",
    "          \n",
    "          # Split the abstract on the period (.)\n",
    "          abstract_lines = sent_tokenize(abstract_text_value)\n",
    "\n",
    "          # Replace the new line characters and remove the extra spaces at the start/end\n",
    "          abstract_lines = [line.replace('\\n','').strip() for line in abstract_lines]\n",
    "\n",
    "          # Remove the empty lines \n",
    "          abstract_lines = [line for line in abstract_lines if len(line) > 0]\n",
    "          \n",
    "          # Evaluate the model\n",
    "          background = ''\n",
    "          objective = ''\n",
    "          methods = ''\n",
    "          results = ''\n",
    "          conclusions = ''\n",
    "\n",
    "          for text in abstract_lines:\n",
    "               text_tensor = text_transform_func(text)\n",
    "               text_tensor = text_tensor.reshape(1, -1)\n",
    "               output = abstract_model(text_tensor)\n",
    "               label = np.argmax(output.detach().cpu().numpy(), axis=1)\n",
    "          \n",
    "               if label == 0:\n",
    "                    background = background + text + ' '\n",
    "               elif label == 1:\n",
    "                    objective = objective + text + ' '\n",
    "               elif label == 2:\n",
    "                    methods = methods + text + ' '\n",
    "               elif label == 3:\n",
    "                    results = results + text + ' '\n",
    "               elif label == 4:\n",
    "                    conclusions = conclusions + text + ' '\n",
    "\n",
    "          background_text.insert(tk.END, background)\n",
    "          objective_text.insert(tk.END, objective)\n",
    "          methods_text.insert(tk.END, methods)\n",
    "          results_text.insert(tk.END, results)\n",
    "          conclusions_text.insert(tk.END, conclusions)\n",
    "        \n",
    "\n",
    "     else: # there is no valid text available in the box\n",
    "          abstract_status_label[\"foreground\"] = \"red\"\n",
    "          abstract_status_label[\"text\"] = \"Invalid Abstract\"\n",
    "         \n",
    "         \n",
    "     return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = tk.Tk()\n",
    "window.title(string=\"Abstract Segmentation System\")\n",
    "window.geometry(\"1200x700\")\n",
    "window.rowconfigure(0, weight=1)\n",
    "window.columnconfigure(0, weight=1)\n",
    "\n",
    "frame_update = tk.Frame(master=window)\n",
    "frame_update.grid(row=0, column=0, sticky='news')\n",
    "frame_update.columnconfigure(0, weight=1, uniform='x')\n",
    "frame_update.columnconfigure(1, weight=1, uniform='x')\n",
    "frame_update.columnconfigure(2, weight=2, uniform='x')\n",
    "frame_update.rowconfigure(0, weight=4, uniform='x')\n",
    "frame_update.rowconfigure(1, weight=1, uniform='x')\n",
    "frame_update.rowconfigure(2, weight=4, uniform='x')\n",
    "frame_update.rowconfigure(3, weight=1, uniform='x')\n",
    "frame_update.rowconfigure(4, weight=4, uniform='x')\n",
    "frame_update.rowconfigure(5, weight=1, uniform='x')\n",
    "frame_update.rowconfigure(6, weight=4, uniform='x')\n",
    "frame_update.rowconfigure(7, weight=1, uniform='x')\n",
    "frame_update.rowconfigure(8, weight=4, uniform='x')\n",
    "frame_update.rowconfigure(9, weight=1, uniform='x')\n",
    "frame_update.rowconfigure(10, weight=4, uniform='x')\n",
    "\n",
    "heading_label = tk.Label(master=frame_update, text=\"ABSTRACT SEGMENTATION SYSTEM\", font=('Open Sans', 32, 'bold'), foreground=\"green\")\n",
    "heading_label.grid(row=0, column=0, columnspan=3, sticky='news')\n",
    "\n",
    "abstract_label = tk.Label(master=frame_update, text=\"Abstract\", font=('Open Sans', 24), foreground= \"purple\")\n",
    "abstract_label.grid(row=2, column=0, sticky='nw', padx=30)\n",
    "\n",
    "reset_button = tk.Button(master=frame_update, text=\"Reset\", font=('Open Sans', 18), width=10, command=clear_all_fields)\n",
    "reset_button.grid(row=2, column=1, sticky=\"nw\", padx=5)\n",
    "\n",
    "abstract_text = tk.Text(master=frame_update, height=30, width=80, font=('Open Sans', 10), wrap='word')\n",
    "abstract_text.grid(row=3, rowspan=6, column=0, columnspan=2, sticky='w', padx=30)\n",
    "\n",
    "process_button = tk.Button(master=frame_update, text=\"Process\", font=('Open Sans', 18), width=10, command=evaluate_model)\n",
    "process_button.grid(row=10, column=0, sticky=\"w\", padx=30)\n",
    "\n",
    "abstract_status_label = tk.Label(master=frame_update, text=\"Upload Abstract\", font=('Open Sans', 16))\n",
    "abstract_status_label.grid(row=12, column=1, sticky='w')\n",
    "\n",
    "background_label = tk.Label(master=frame_update, text=\"Background\", font=('Open Sans', 18), foreground= \"purple\")\n",
    "background_label.grid(row=1, column=2, sticky='w')\n",
    "\n",
    "background_text = tk.Text(master=frame_update, height=4, width=70, font=('Open Sans', 10), wrap='word')\n",
    "background_text.grid(row=2, column=2, sticky='w')\n",
    "\n",
    "objective_label = tk.Label(master=frame_update, text=\"Objective\", font=('Open Sans', 18), foreground= \"purple\")\n",
    "objective_label.grid(row=3, column=2, sticky='w')\n",
    "\n",
    "objective_text = tk.Text(master=frame_update, height=4, width=70, font=('Open Sans', 10), wrap='word')\n",
    "objective_text.grid(row=4, column=2, sticky='w')\n",
    "\n",
    "methods_label = tk.Label(master=frame_update, text=\"Methods\", font=('Open Sans', 18), foreground= \"purple\")\n",
    "methods_label.grid(row=5, column=2, sticky='w')\n",
    "\n",
    "methods_text = tk.Text(master=frame_update, height=4, width=70, font=('Open Sans', 10), wrap='word')\n",
    "methods_text.grid(row=6, column=2, sticky='w')\n",
    "\n",
    "results_label = tk.Label(master=frame_update, text=\"Results\", font=('Open Sans', 18), foreground= \"purple\")\n",
    "results_label.grid(row=7, column=2, sticky='w')\n",
    "\n",
    "results_text = tk.Text(master=frame_update, height=4, width=70, font=('Open Sans', 10), wrap='word')\n",
    "results_text.grid(row=8, column=2, sticky='w')\n",
    "\n",
    "conclusions_label = tk.Label(master=frame_update, text=\"Conclusions\", font=('Open Sans', 18), foreground= \"purple\")\n",
    "conclusions_label.grid(row=9, column=2, sticky='w')\n",
    "\n",
    "conclusions_text = tk.Text(master=frame_update, height=4, width=70, font=('Open Sans', 10), wrap='word')\n",
    "conclusions_text.grid(row=10, column=2, sticky='w')\n",
    "\n",
    "# Clearing up all the text fields at the start\n",
    "abstract_text.delete(1.0, tk.END)\n",
    "abstract_status_label[\"text\"] = \"\"\n",
    "background_text.delete(1.0, tk.END)\n",
    "objective_text.delete(1.0, tk.END)\n",
    "methods_text.delete(1.0, tk.END)\n",
    "results_text.delete(1.0, tk.END)\n",
    "conclusions_text.delete(1.0, tk.END)\n",
    "\n",
    "frame_update.tkraise()\n",
    "window.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning_general",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
