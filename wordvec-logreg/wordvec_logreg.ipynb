{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dxxo4zfUOnhP",
        "outputId": "08586a90-811b-425c-e9f3-1801e86803fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.7758101142712672\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "# Load text data from CSV file\n",
        "data = pd.read_csv('csv/train.csv')\n",
        "\n",
        "# Preprocess text data (tokenization, lowercasing)\n",
        "data['Text'] = data['Text'].apply(lambda x: x.lower().split())  # Tokenization and lowercasing\n",
        "\n",
        "# Build Word2Vec vocabulary\n",
        "word2vec_model = Word2Vec(sentences=data['Text'].to_list(), vector_size=100, window=5, min_count=1, workers=4)\n",
        "#word2vec_model.build_vocab(data['Text'])\n",
        "\n",
        "# Train Word2Vec model\n",
        "word2vec_model.train(data['Text'], total_examples=word2vec_model.corpus_count, epochs=10)  # Train the model\n",
        "\n",
        "# Generate Word2Vec embeddings for each document\n",
        "def average_word_vectors(words, model, vocabulary, num_features):\n",
        "    feature_vector = np.zeros((num_features,), dtype=\"float64\")\n",
        "    nwords = 0\n",
        "    for word in words:\n",
        "        if word in vocabulary:\n",
        "            nwords += 1\n",
        "            feature_vector = np.add(feature_vector, model.wv[word])\n",
        "    if nwords:\n",
        "        feature_vector = np.divide(feature_vector, nwords)\n",
        "    return feature_vector\n",
        "\n",
        "X = [average_word_vectors(words, word2vec_model, word2vec_model.wv.index_to_key, 100) for words in data['Text']]\n",
        "y = data['Label']\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression using Word2Vec embeddings\n",
        "classifier = LogisticRegression(max_iter=1000)\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test set\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Calculate accurary\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "C0L1UTYy_X6m",
        "outputId": "2d65c67b-5a44-405c-f012-8648ad2a0eac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision: 0.7758\n",
            "Recall: 0.7758\n",
            "F1-score: 0.7758\n"
          ]
        }
      ],
      "source": [
        "from gensim.models import Word2Vec\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# Calculate precision, recall, and F1-score\n",
        "precision = precision_score(y_test, y_pred, average='micro')\n",
        "recall = recall_score(y_test, y_pred, average='micro')\n",
        "f1 = f1_score(y_test, y_pred, average='micro')\n",
        "\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print(f'F1-score: {f1:.4f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "  BACKGROUND       0.56      0.43      0.49     38306\n",
            " CONCLUSIONS       0.67      0.71      0.69     67498\n",
            "     METHODS       0.83      0.88      0.85    143047\n",
            "   OBJECTIVE       0.64      0.58      0.61     37057\n",
            "     RESULTS       0.85      0.84      0.85    153135\n",
            "\n",
            "    accuracy                           0.78    439043\n",
            "   macro avg       0.71      0.69      0.70    439043\n",
            "weighted avg       0.77      0.78      0.77    439043\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 16662   9939   3346   7484    875]\n",
            " [  4992  47781   3040   2481   9204]\n",
            " [  1440   1863 125392   1830  12522]\n",
            " [  6230   4939   3861  21450    577]\n",
            " [   588   7105  15706    407 129329]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "print(confusion_matrix(y_test, y_pred))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
